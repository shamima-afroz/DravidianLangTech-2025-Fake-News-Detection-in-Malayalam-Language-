{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h15s-hepXj27",
        "outputId": "c19d2305-bc32-4569-f8a0-70f1f8251ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11 s, sys: 2.14 s, total: 13.1 s\n",
            "Wall time: 16.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
        "from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "np.random.seed(42)\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "import nltk, string, re, spacy,unicodedata, random\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('/content/Fake_train.csv', encoding='utf-8')\n",
        "test_df = pd.read_csv('/content/Fake_test_without_labels.csv', encoding='utf-8')\n",
        "df2 = pd.read_csv('/content/Fake_dev.csv', encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "smWR9gwBXypF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "df = pd.read_csv('/content/Fake_train.csv')\n",
        "\n",
        "# Displaying DataFrame in Colab\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "aBtkgVstXytd",
        "outputId": "446ee319-adf3-492d-dc5d-d84aa5e024b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text     label\n",
              "0                     ‡¥®‡¥≤‡µç‡¥≤ ‡¥Ö‡¥µ‡¥§‡¥∞‡¥£‡¥Ç. ‡¥∏‡¥§‡µç‡¥Ø‡¥Ç ‡¥™‡µÅ‡¥±‡¥§‡µç‡¥§‡µÅ ‡¥µ‡¥∞‡¥ü‡µç‡¥ü‡µÜ      Fake\n",
              "1                                           Masha Allah      Fake\n",
              "2     ‡¥Ö‡¥®‡µç‡¥µ‡µá‡¥∑‡¥£‡¥Ç ‡¥ï‡¥¥‡¥ø‡¥Ø‡µÅ‡¥Æ‡µç‡¥™‡µã‡µæ,. C. A. A. ‡¥Ø‡µç‡¥ï‡µç‡¥ï‡µç ‡¥é‡¥§‡¥ø‡¥∞‡¥æ‡¥Ø ‡¥ï...      Fake\n",
              "3       Illathentha avaru purath vidayittalland verenth      Fake\n",
              "4     Barana pakshathin matoru niyamam.nalla moyanth...  original\n",
              "...                                                 ...       ...\n",
              "3252  ‡¥µ‡µÄ‡¥£‡¥æ ‡¥ú‡µã‡µº‡¥ú‡µç ‡¥é‡¥®‡µç‡¥® ‡¥í‡¥∞‡µÅ ‡¥Ü‡¥∞‡µã‡¥ó‡µç‡¥Ø ‡¥Æ‡¥®‡µç‡¥§‡µç‡¥∞‡¥ø ‡¥µ‡¥®‡µç‡¥®‡¥§‡¥ø‡¥®‡µÅ ‡¥∂‡µá...  original\n",
              "3253                                 ‡¥á‡¥§‡¥æ‡¥£‡µç ‡¥™‡¥ø‡¥£‡µÅ‡¥µ‡¥æ‡¥§‡¥ø‡¥∞üòÇüòÇüòÇ  original\n",
              "3254                                   ‡¥ï‡µá‡¥∏‡µç ‡¥é‡¥ü‡µÅ‡¥ï‡µç‡¥ï‡¥£‡¥Ç üíØüëç  original\n",
              "3255      ‡¥é‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µç‡¥§‡¥ø‡¥®‡µá‡¥Ç 501 ‡¥∏‡µã‡¥™‡µç‡¥™‡¥ø‡¥ü‡µç‡¥ü‡µç ‡¥ï‡¥≥‡¥ø‡¥™‡µç‡¥™‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥µ‡¥ø‡¥ü‡¥£‡¥Ç  original\n",
              "3256  Day by day leaders r acting like a fool in dev...  original\n",
              "\n",
              "[3257 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7927e73-c7eb-4933-af8c-1a417d161412\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡¥®‡¥≤‡µç‡¥≤ ‡¥Ö‡¥µ‡¥§‡¥∞‡¥£‡¥Ç. ‡¥∏‡¥§‡µç‡¥Ø‡¥Ç ‡¥™‡µÅ‡¥±‡¥§‡µç‡¥§‡µÅ ‡¥µ‡¥∞‡¥ü‡µç‡¥ü‡µÜ</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Masha Allah</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡¥Ö‡¥®‡µç‡¥µ‡µá‡¥∑‡¥£‡¥Ç ‡¥ï‡¥¥‡¥ø‡¥Ø‡µÅ‡¥Æ‡µç‡¥™‡µã‡µæ,. C. A. A. ‡¥Ø‡µç‡¥ï‡µç‡¥ï‡µç ‡¥é‡¥§‡¥ø‡¥∞‡¥æ‡¥Ø ‡¥ï...</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Illathentha avaru purath vidayittalland verenth</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Barana pakshathin matoru niyamam.nalla moyanth...</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3252</th>\n",
              "      <td>‡¥µ‡µÄ‡¥£‡¥æ ‡¥ú‡µã‡µº‡¥ú‡µç ‡¥é‡¥®‡µç‡¥® ‡¥í‡¥∞‡µÅ ‡¥Ü‡¥∞‡µã‡¥ó‡µç‡¥Ø ‡¥Æ‡¥®‡µç‡¥§‡µç‡¥∞‡¥ø ‡¥µ‡¥®‡µç‡¥®‡¥§‡¥ø‡¥®‡µÅ ‡¥∂‡µá...</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3253</th>\n",
              "      <td>‡¥á‡¥§‡¥æ‡¥£‡µç ‡¥™‡¥ø‡¥£‡µÅ‡¥µ‡¥æ‡¥§‡¥ø‡¥∞üòÇüòÇüòÇ</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3254</th>\n",
              "      <td>‡¥ï‡µá‡¥∏‡µç ‡¥é‡¥ü‡µÅ‡¥ï‡µç‡¥ï‡¥£‡¥Ç üíØüëç</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3255</th>\n",
              "      <td>‡¥é‡¥≤‡µç‡¥≤‡¥æ‡¥§‡µç‡¥§‡¥ø‡¥®‡µá‡¥Ç 501 ‡¥∏‡µã‡¥™‡µç‡¥™‡¥ø‡¥ü‡µç‡¥ü‡µç ‡¥ï‡¥≥‡¥ø‡¥™‡µç‡¥™‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥µ‡¥ø‡¥ü‡¥£‡¥Ç</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3256</th>\n",
              "      <td>Day by day leaders r acting like a fool in dev...</td>\n",
              "      <td>original</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3257 rows √ó 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7927e73-c7eb-4933-af8c-1a417d161412')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b7927e73-c7eb-4933-af8c-1a417d161412 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b7927e73-c7eb-4933-af8c-1a417d161412');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df39bf47-08ba-40c1-b5a4-7b5ebc470480\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df39bf47-08ba-40c1-b5a4-7b5ebc470480')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df39bf47-08ba-40c1-b5a4-7b5ebc470480 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_871ceb14-ca55-4a53-9c0f-229d2d948aac\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_871ceb14-ca55-4a53-9c0f-229d2d948aac button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3257,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3186,\n        \"samples\": [\n          \"\\u0d24\\u0d3e\\u0d19\\u0d4d\\u0d15\\u0d7e.... \\u0d35\\u0d48\\u0d31\\u0d4b\\u0d33\\u0d3f\\u0d1c\\u0d3f\\u0d38\\u0d4d\\u0d31\\u0d4d \\u0d28\\u0d4d... \\u0d21\\u0d4b\\u0d15\\u0d4d\\u0d1f\\u0d7c \\u0d2e\\u0d3e\\u0d30\\u0d46... \\u0d28\\u0d3f\\u0d30\\u0d3e\\u0d36 \\u0d2a\\u0d46\\u0d1f\\u0d41\\u0d24\\u0d4d\\u0d24\\u0d3f \\u0d35\\u0d3e\\u0d15\\u0d4d\\u200c\\u0d38\\u0d3f\\u0d7b \\u0d15\\u0d23\\u0d4d\\u0d1f\\u0d41 \\u0d2a\\u0d3f\\u0d1f\\u0d3f\\u0d15\\u0d4d\\u0d15\\u0d41\\u0d28\\u0d4d\\u0d28\\u0d35\\u0d7c... \\u0d09\\u0d26\\u0d3e\\u0d38\\u0d40\\u0d28\\u0d24 \\u0d09\\u0d23\\u0d4d\\u0d1f\\u0d3e\\u0d15\\u0d4d\\u0d15\\u0d41\\u0d02... \\u0d07\\u0d24\\u0d41 \\u0d2a\\u0d4b\\u0d32\\u0d41\\u0d33\\u0d4d\\u0d33... \\u0d28\\u0d3f\\u0d32\\u0d2a\\u0d3e\\u0d1f\\u0d4d \\u0d35\\u0d47\\u0d23\\u0d4d\\u0d1f... \\u0d15\\u0d4a\\u0d31\\u0d4b\\u0d23 \\u0d2a\\u0d4b\\u0d15\\u0d41\\u0d28\\u0d4d\\u0d28\\u0d41 \\u0d09\\u0d23\\u0d4d\\u0d1f\\u0d4d \\u0d0e\\u0d19\\u0d4d\\u0d15\\u0d3f\\u0d7d \\u0d2a\\u0d4b\\u0d15\\u0d1f\\u0d4d\\u0d1f\\u0d46... \\u0d06\\u0d30\\u0d41\\u0d02 \\u0d24\\u0d1f\\u0d38\\u0d4d\\u0d38\\u0d02 \\u0d2a\\u0d31\\u0d2f\\u0d3f\\u0d32\\u0d4d\\u0d32...\",\n          \"\\u0d24\\u0d3e\\u0d19\\u0d4d\\u0d15\\u0d33\\u0d46 \\u0d15\\u0d41\\u0d31\\u0d4d\\u0d31\\u0d02 \\u0d2a\\u0d31\\u0d1e\\u0d4d\\u0d1e\\u0d3f\\u0d1f\\u0d4d\\u0d1f\\u0d4d \\u0d15\\u0d3e\\u0d30\\u0d4d\\u0d2f\\u0d2e\\u0d3f\\u0d32\\u0d4d\\u0d32 \\u0d28\\u0d32\\u0d4d\\u0d32 \\u0d15\\u0d3e\\u0d30\\u0d4d\\u0d2f\\u0d19\\u0d4d\\u0d19\\u0d33\\u0d46  \\u0d24\\u0d3f\\u0d30\\u0d3f\\u0d1a\\u0d4d\\u0d1a\\u0d31\\u0d3f\\u0d2f\\u0d3e\\u0d7b  \\u0d28\\u0d32\\u0d4d\\u0d32 \\u0d2e\\u0d28\\u0d41\\u0d37\\u0d4d\\u0d2f\\u0d7c\\u0d15\\u0d46  \\u0d15\\u0d34\\u0d3f\\u0d2f\\u0d42 \\u0d05\\u0d24\\u0d4d  \\u0d2a\\u0d4d\\u0d30\\u0d15\\u0d43\\u0d24\\u0d3f \\u0d28\\u0d3f\\u0d2f\\u0d2e\\u0d2e\\u0d3e\\u0d23\\u0d4d \\u0d08 \\u0d32\\u0d4b\\u0d15\\u0d24\\u0d4d\\u0d24\\u0d4d \\u0d05\\u0d24\\u0d4d \\u0d2a\\u0d4b\\u0d38\\u0d3f\\u0d31\\u0d4d\\u0d31\\u0d40\\u0d35\\u0d4d \\u0d2e\\u0d3e\\u0d24\\u0d4d\\u0d30\\u0d02 \\u0d2a\\u0d4b\\u0d30 \\u0d28\\u0d46\\u0d17\\u0d31\\u0d4d\\u0d31\\u0d40\\u0d35\\u0d4d \\u0d35\\u0d47\\u0d23\\u0d02 \\u0d05\\u0d24\\u0d41\\u0d02 \\u0d12\\u0d30\\u0d41 \\u0d2f\\u0d3e\\u0d25\\u0d3e\\u0d7c\\u0d24\\u0d4d\\u0d25\\u0d4d\\u0d2f\\u0d2e\\u0d3e\\u0d23\\u0d4d \\u0d05\\u0d24\\u0d41\\u0d15\\u0d4a\\u0d23\\u0d4d\\u0d1f\\u0d4d \\u0d24\\u0d3e\\u0d19\\u0d4d\\u0d15\\u0d33\\u0d46\\u0d2a\\u0d4d\\u0d2a\\u0d4b\\u0d32\\u0d41\\u0d33\\u0d4d\\u0d33\\u0d35\\u0d7c \\u0d08 \\u0d2d\\u0d42\\u0d2e\\u0d3f\\u0d2f\\u0d3f\\u0d7d \\u0d06\\u0d35\\u0d36\\u0d4d\\u0d2f\\u0d2e\\u0d3e\\u0d23\\u0d4d\",\n          \"\\u0d15\\u0d47\\u0d28\\u0d4d\\u0d26\\u0d4d\\u0d30\\u0d35\\u0d41\\u0d02 \\u0d15\\u0d23\\u0d15\\u0d4d\\u0d15\\u0d4d.... \\u0d38\\u0d02\\u0d38\\u0d4d\\u0d25\\u0d3e\\u0d28 \\u0d38\\u0d7c\\u0d15\\u0d4d\\u0d15\\u0d3e\\u0d31\\u0d41\\u0d02.... \\u0d07\\u0d35\\u0d2e\\u0d4d\\u0d2e\\u0d3e\\u0d30\\u0d46\\u0d2f\\u0d4a\\u0d15\\u0d4d\\u0d15 elect \\u0d1a\\u0d46\\u0d2f\\u0d4d\\u0d24 \\u0d28\\u0d2e\\u0d4d\\u0d2e\\u0d33\\u0d46 \\u0d2a\\u0d31\\u0d1e\\u0d4d\\u0d1e\\u0d7d \\u0d2e\\u0d24\\u0d3f....\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"original\",\n          \"Fake\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "text_column = 'text'\n",
        "label_column = 'label'\n",
        "train_df[text_column] = train_df[text_column].fillna('')\n",
        "test_df[text_column] = test_df[text_column].fillna('')"
      ],
      "metadata": {
        "id": "909yIlybXyxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "max_vocab_size = 10000\n",
        "max_sequence_length = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_df[text_column])\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(train_df[text_column])\n",
        "X_test = tokenizer.texts_to_sequences(test_df[text_column])\n",
        "X_train = pad_sequences(X_train, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGS46ll7XzCb",
        "outputId": "e23f853f-c03d-4f49-8fdc-391b427c71d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  38,  328,  111, ...,    0,    0,    0],\n",
              "       [4551, 1629,    0, ...,    0,    0,    0],\n",
              "       [4552, 1229, 1630, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 184, 4430,    1, ...,    0,    0,    0],\n",
              "       [   1,  891,    1, ...,    0,    0,    0],\n",
              "       [ 739,  127,  739, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_df[label_column])\n",
        "print(train_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxxzQQXvXzN4",
        "outputId": "91abdeb5-9311-4cd9-a064-32bcb2507678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "original    1658\n",
            "Fake        1599\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to a new CSV file\n",
        "train_df.to_csv('/content/Preprocessed_Fake_train.csv', index=False, encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "fnAsUVSyZu4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train and dev data\n",
        "X_train = tokenizer.texts_to_sequences(train_df[text_column])\n",
        "X_dev = tokenizer.texts_to_sequences(df2[text_column])  # Assuming 'df2' is your dev dataset\n",
        "\n",
        "# Pad sequences\n",
        "X_train = pad_sequences(X_train, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "X_dev = pad_sequences(X_dev, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "# Label encoding for dev set\n",
        "y_dev = label_encoder.transform(df2[label_column])  # Using same encoder as for the train set\n"
      ],
      "metadata": {
        "id": "0G-depnyZu8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regrression using tfidf\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load your preprocessed data\n",
        "\n",
        "# Load training, validation, and test data\n",
        "train_df = pd.read_csv('/content/Fake_train.csv')\n",
        "test_data = pd.read_csv('/content/Fake_test_without_labels.csv')\n",
        "df2 = pd.read_csv('/content/Fake_dev.csv')\n",
        "\n",
        "# Set the column names for text and labels\n",
        "text_column = 'text'\n",
        "label_column = 'label'\n",
        "\n",
        "# Step 2: TF-IDF Vectorization\n",
        "max_vocab_size = 10000\n",
        "vectorizer = TfidfVectorizer(max_features=max_vocab_size)\n",
        "\n",
        "# Vectorize the datasets\n",
        "X_train = vectorizer.fit_transform(train_df[text_column])\n",
        "X_dev = vectorizer.transform(df2[text_column])\n",
        "X_test = vectorizer.transform(test_data[text_column])\n",
        "\n",
        "# Step 3: Label encoding for train and dev sets\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_df[label_column])\n",
        "y_dev = label_encoder.transform(df2[label_column])\n",
        "\n",
        "# Step 4: Compute class weights for balanced classes\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Step 5: Define and train the Logistic Regression model\n",
        "model_lr = LogisticRegression(C=0.01, max_iter=1000, class_weight='balanced', random_state=42)\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Evaluate the model on the dev set\n",
        "y_dev_pred = model_lr.predict(X_dev)\n",
        "\n",
        "# Print evaluation metrics for the dev set\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_dev, y_dev_pred))\n",
        "print(\"Classification Report on Dev Set:\")\n",
        "print(classification_report(y_dev, y_dev_pred))\n",
        "\n",
        "# Step 7: Make predictions on the test set\n",
        "y_test_pred = model_lr.predict(X_test)\n",
        "\n",
        "# Convert predictions to 'Fake' or 'Original' labels\n",
        "test_labels = ['Fake' if label == 0 else 'original' for label in y_test_pred]\n",
        "\n",
        "# Step 8: Add predictions to the test dataframe and save results\n",
        "test_data['predicted_label'] = test_labels\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "output_path = '/content/logistic_regression_predicted_test.csv'\n",
        "test_data.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_path}\")\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the predicted and actual files\n",
        "predicted_file = pd.read_csv('/content/logistic_regression_predicted_test.csv')  # Predicted labels\n",
        "actual_file = pd.read_csv('/content/Fake_test_with_labels.csv')  # Actual labels\n",
        "\n",
        "# Verify column names in the predicted and actual files\n",
        "print(\"Predicted file columns:\", predicted_file.columns)\n",
        "print(\"Actual file columns:\", actual_file.columns)\n",
        "\n",
        "# Create the 'Id' column in the actual file\n",
        "# Assuming the row order corresponds to IDs like Fake_01, Fake_02, ...\n",
        "actual_file['Id'] = ['Fake_{:02d}'.format(i + 1) for i in range(len(actual_file))]\n",
        "\n",
        "# Verify the 'Id' column\n",
        "print(\"Actual file with 'Id' column:\")\n",
        "print(actual_file.head())\n",
        "\n",
        "# Merge the predicted file with the actual file on the 'Id' column\n",
        "merged = pd.merge(predicted_file, actual_file, on='Id')\n",
        "\n",
        "# Extract the true labels and predicted labels from the merged DataFrame\n",
        "y_true = merged['label']  # Actual labels\n",
        "y_pred = merged['predicted_label']  # Predicted labels\n",
        "\n",
        "# Compare predictions and compute evaluation metrics\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Save the merged file with comparison for review (optional)\n",
        "merged.to_csv('/content/logistic_regression_merged_comparison.csv', index=False)\n",
        "print(\"Merged comparison file saved to /content/logistic_regression_merged_comparison.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlGck9ETb0SM",
        "outputId": "8b875042-e4f9-4e28-9050-63458cbb363f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7607361963190185\n",
            "Classification Report on Dev Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.71      0.75       406\n",
            "           1       0.74      0.81      0.77       409\n",
            "\n",
            "    accuracy                           0.76       815\n",
            "   macro avg       0.76      0.76      0.76       815\n",
            "weighted avg       0.76      0.76      0.76       815\n",
            "\n",
            "Predictions saved to /content/logistic_regression_predicted_test.csv\n",
            "Predicted file columns: Index(['Id', 'text', 'predicted_label'], dtype='object')\n",
            "Actual file columns: Index(['text', 'label'], dtype='object')\n",
            "Actual file with 'Id' column:\n",
            "                                                text     label       Id\n",
            "0  5000 ‡¥â‡¥≥‡µç‡¥≥ ‡¥™‡µã‡µæ  ‡¥≤‡µã‡¥ó‡µç‚Äå‡¥°‡µç‚Äå‡¥µ‡µª ‡¥á‡¥™‡µç‡¥™‡µã‡¥≥‡µç 250000 ‡¥é‡¥®‡µç‡¥§‡¥æ...      Fake  Fake_01\n",
            "1  ‡¥ì‡¥∑‡µã ‡¥∞‡¥ú‡¥®‡µÄ‡¥∑‡µç  ‡¥™‡¥±‡¥û‡µç‡¥û‡¥™‡µã‡¥≤‡µÜ  ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡¥™‡µç‡¥™‡µã‡µæ ‡¥§‡µã‡¥®‡µç‡¥®‡¥ø‡¥Ø‡¥§‡µç ‡¥Ö...      Fake  Fake_02\n",
            "2  ‡¥ö‡µá‡¥ü‡µç‡¥ü‡¥æ  ‡¥µ‡¥æ‡µº‡¥§‡µç‡¥§  ‡¥µ‡¥Ø‡µç‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡¥§‡µç  ‡¥ï‡µá‡¥∞‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡¥æ‡¥£‡µç  ‡¥∏‡¥Ç...      Fake  Fake_03\n",
            "3             Shame for entire Woman&#39;s of Kerala  original  Fake_04\n",
            "4  135 code janaghal andhu wide business cheythal...      Fake  Fake_05\n",
            "Accuracy: 0.746810598626104\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.77      0.70      0.73       507\n",
            "    original       0.73      0.79      0.76       512\n",
            "\n",
            "    accuracy                           0.75      1019\n",
            "   macro avg       0.75      0.75      0.75      1019\n",
            "weighted avg       0.75      0.75      0.75      1019\n",
            "\n",
            "Merged comparison file saved to /content/logistic_regression_merged_comparison.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load your preprocessed data\n",
        "\n",
        "# Load training, validation, and test data\n",
        "train_df = pd.read_csv('/content/Fake_train.csv')\n",
        "test_data = pd.read_csv('/content/Fake_test_without_labels.csv')\n",
        "df2 = pd.read_csv('/content/Fake_dev.csv')\n",
        "\n",
        "# Set the column names for text and labels\n",
        "text_column = 'text'\n",
        "label_column = 'label'\n",
        "\n",
        "# Step 2: TF-IDF Vectorization\n",
        "max_vocab_size = 10000\n",
        "vectorizer = TfidfVectorizer(max_features=max_vocab_size)\n",
        "\n",
        "# Vectorize the datasets\n",
        "X_train = vectorizer.fit_transform(train_df[text_column])\n",
        "X_dev = vectorizer.transform(df2[text_column])\n",
        "X_test = vectorizer.transform(test_data[text_column])\n",
        "\n",
        "# Step 3: Label encoding for train and dev sets\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_df[label_column])\n",
        "y_dev = label_encoder.transform(df2[label_column])\n",
        "\n",
        "# Step 4: Compute class weights for balanced classes\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Step 5: Define and train the Decision Tree model\n",
        "model_dt = DecisionTreeClassifier(max_depth=10, class_weight='balanced', random_state=42)\n",
        "model_dt.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Evaluate the model on the dev set\n",
        "y_dev_pred = model_dt.predict(X_dev)\n",
        "\n",
        "# Print evaluation metrics for the dev set\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_dev, y_dev_pred))\n",
        "print(\"Classification Report on Dev Set:\")\n",
        "print(classification_report(y_dev, y_dev_pred))\n",
        "\n",
        "# Step 7: Make predictions on the test set\n",
        "y_test_pred = model_dt.predict(X_test)\n",
        "\n",
        "# Convert predictions to 'Fake' or 'Original' labels\n",
        "test_labels = ['Fake' if label == 0 else 'original' for label in y_test_pred]\n",
        "\n",
        "# Step 8: Add predictions to the test dataframe and save results\n",
        "test_data['predicted_label'] = test_labels\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "output_path = '/content/decision_tree_predicted_test.csv'\n",
        "test_data.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_path}\")\n",
        "\n",
        "# Merging to compare with actual labels\n",
        "\n",
        "# Load the predicted and actual files\n",
        "predicted_file = pd.read_csv('/content/decision_tree_predicted_test.csv')\n",
        "actual_file = pd.read_csv('/content/Fake_test_with_labels.csv')\n",
        "\n",
        "# Verify column names in the predicted and actual files\n",
        "print(\"Predicted file columns:\", predicted_file.columns)\n",
        "print(\"Actual file columns:\", actual_file.columns)\n",
        "\n",
        "# Create the 'Id' column in the actual file\n",
        "actual_file['Id'] = ['Fake_{:02d}'.format(i + 1) for i in range(len(actual_file))]\n",
        "\n",
        "# Merge the predicted file with the actual file on the 'Id' column\n",
        "merged = pd.merge(predicted_file, actual_file, on='Id')\n",
        "\n",
        "# Extract the true labels and predicted labels from the merged DataFrame\n",
        "y_true = merged['label']\n",
        "y_pred = merged['predicted_label']\n",
        "\n",
        "# Compare predictions and compute evaluation metrics\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Save the merged file with comparison for review (optional)\n",
        "merged.to_csv('/content/decision_tree_merged_comparison.csv', index=False)\n",
        "print(\"Merged comparison file saved to /content/decision_tree_merged_comparison.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYK5C2oke8Dh",
        "outputId": "76e373df-5fbd-42ea-c497-314fc2292425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.6466257668711657\n",
            "Classification Report on Dev Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.33      0.49       406\n",
            "           1       0.59      0.96      0.73       409\n",
            "\n",
            "    accuracy                           0.65       815\n",
            "   macro avg       0.74      0.65      0.61       815\n",
            "weighted avg       0.74      0.65      0.61       815\n",
            "\n",
            "Predictions saved to /content/decision_tree_predicted_test.csv\n",
            "Predicted file columns: Index(['Id', 'text', 'predicted_label'], dtype='object')\n",
            "Actual file columns: Index(['text', 'label'], dtype='object')\n",
            "Accuracy: 0.6300294406280668\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.86      0.31      0.45       507\n",
            "    original       0.58      0.95      0.72       512\n",
            "\n",
            "    accuracy                           0.63      1019\n",
            "   macro avg       0.72      0.63      0.59      1019\n",
            "weighted avg       0.72      0.63      0.59      1019\n",
            "\n",
            "Merged comparison file saved to /content/decision_tree_merged_comparison.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Load your preprocessed data\n",
        "train_df = pd.read_csv('/content/Fake_train.csv')\n",
        "test_data = pd.read_csv('/content/Fake_test_without_labels.csv')\n",
        "df2 = pd.read_csv('/content/Fake_dev.csv')\n",
        "\n",
        "# Set the column names for text and labels\n",
        "text_column = 'text'\n",
        "label_column = 'label'\n",
        "\n",
        "# Preprocess the data using TF-IDF Vectorization\n",
        "max_vocab_size = 10000\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=max_vocab_size)\n",
        "\n",
        "# Fit and transform the train data, transform dev and test data\n",
        "X_train = vectorizer.fit_transform(train_df[text_column]).toarray()\n",
        "X_dev = vectorizer.transform(df2[text_column]).toarray()\n",
        "X_test = vectorizer.transform(test_data[text_column]).toarray()\n",
        "\n",
        "# Label encoding for train and dev sets\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_df[label_column])\n",
        "y_dev = label_encoder.transform(df2[label_column])\n",
        "\n",
        "# Step 2: Compute class weights for balanced classes\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Step 3: Define and train the SVM model\n",
        "model_svm = SVC(class_weight='balanced', kernel='linear', random_state=42)\n",
        "model_svm.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the model on the dev set\n",
        "y_dev_pred = model_svm.predict(X_dev)\n",
        "\n",
        "# Print evaluation metrics for the dev set\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_dev, y_dev_pred))\n",
        "print(\"Classification Report on Dev Set:\")\n",
        "print(classification_report(y_dev, y_dev_pred))\n",
        "\n",
        "# Step 5: Make predictions on the test set\n",
        "y_test_pred = model_svm.predict(X_test)\n",
        "\n",
        "# Convert predictions to 'Fake' or 'Original' labels\n",
        "test_labels = ['Fake' if label == 0 else 'original' for label in y_test_pred]\n",
        "\n",
        "# Step 6: Add predictions to the test dataframe and save results\n",
        "test_data['predicted_label'] = test_labels\n",
        "\n",
        "# Save predictions to a new CSV file\n",
        "output_path = '/content/svm_predicted_test.csv'\n",
        "test_data.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_path}\")\n",
        "\n",
        "# Merging to compare with actual labels\n",
        "# Load the predicted and actual files\n",
        "predicted_file = pd.read_csv('/content/svm_predicted_test.csv')  # Predicted labels\n",
        "actual_file = pd.read_csv('/content/Fake_test_with_labels.csv')  # Actual labels\n",
        "\n",
        "# Verify column names in the predicted and actual files\n",
        "print(\"Predicted file columns:\", predicted_file.columns)\n",
        "print(\"Actual file columns:\", actual_file.columns)\n",
        "\n",
        "# Create the 'Id' column in the actual file\n",
        "# Assuming the row order corresponds to IDs like Fake_01, Fake_02, ...\n",
        "actual_file['Id'] = ['Fake_{:02d}'.format(i + 1) for i in range(len(actual_file))]\n",
        "\n",
        "# Verify the 'Id' column\n",
        "print(\"Actual file with 'Id' column:\")\n",
        "print(actual_file.head())\n",
        "\n",
        "# Merge the predicted file with the actual file on the 'Id' column\n",
        "merged = pd.merge(predicted_file, actual_file, on='Id')\n",
        "\n",
        "# Extract the true labels and predicted labels from the merged DataFrame\n",
        "y_true = merged['label']  # Actual labels\n",
        "y_pred = merged['predicted_label']  # Predicted labels\n",
        "\n",
        "# Compare predictions and compute evaluation metrics\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Save the merged file with comparison for review (optional)\n",
        "merged.to_csv('/content/svm_merged_comparison.csv', index=False)\n",
        "print(\"Merged comparison file saved to /content/svm_merged_comparison.csv\")\n"
      ],
      "metadata": {
        "id": "Be_7d6iIZvWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae1c9f4-0c3a-4155-b7b6-563a1dd1e141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7815950920245399\n",
            "Classification Report on Dev Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.76      0.78       406\n",
            "           1       0.77      0.80      0.79       409\n",
            "\n",
            "    accuracy                           0.78       815\n",
            "   macro avg       0.78      0.78      0.78       815\n",
            "weighted avg       0.78      0.78      0.78       815\n",
            "\n",
            "Predictions saved to /content/svm_predicted_test.csv\n",
            "Predicted file columns: Index(['Id', 'text', 'predicted_label'], dtype='object')\n",
            "Actual file columns: Index(['text', 'label'], dtype='object')\n",
            "Actual file with 'Id' column:\n",
            "                                                text     label       Id\n",
            "0  5000 ‡¥â‡¥≥‡µç‡¥≥ ‡¥™‡µã‡µæ  ‡¥≤‡µã‡¥ó‡µç‚Äå‡¥°‡µç‚Äå‡¥µ‡µª ‡¥á‡¥™‡µç‡¥™‡µã‡¥≥‡µç 250000 ‡¥é‡¥®‡µç‡¥§‡¥æ...      Fake  Fake_01\n",
            "1  ‡¥ì‡¥∑‡µã ‡¥∞‡¥ú‡¥®‡µÄ‡¥∑‡µç  ‡¥™‡¥±‡¥û‡µç‡¥û‡¥™‡µã‡¥≤‡µÜ  ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡¥™‡µç‡¥™‡µã‡µæ ‡¥§‡µã‡¥®‡µç‡¥®‡¥ø‡¥Ø‡¥§‡µç ‡¥Ö...      Fake  Fake_02\n",
            "2  ‡¥ö‡µá‡¥ü‡µç‡¥ü‡¥æ  ‡¥µ‡¥æ‡µº‡¥§‡µç‡¥§  ‡¥µ‡¥Ø‡µç‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡¥§‡µç  ‡¥ï‡µá‡¥∞‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥≤‡¥æ‡¥£‡µç  ‡¥∏‡¥Ç...      Fake  Fake_03\n",
            "3             Shame for entire Woman&#39;s of Kerala  original  Fake_04\n",
            "4  135 code janaghal andhu wide business cheythal...      Fake  Fake_05\n",
            "Accuracy: 0.7585868498527969\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.77      0.73      0.75       507\n",
            "    original       0.75      0.78      0.77       512\n",
            "\n",
            "    accuracy                           0.76      1019\n",
            "   macro avg       0.76      0.76      0.76      1019\n",
            "weighted avg       0.76      0.76      0.76      1019\n",
            "\n",
            "Merged comparison file saved to /content/svm_merged_comparison.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0iNzUInZvZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eUj9tbslZvdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wBtlZt5uZvgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GLhKZsSwZvkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Is6AmtVZvpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjtwUNtpZvty"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}